{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db303113",
   "metadata": {},
   "source": [
    "Q2. USA House Pricing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565508d",
   "metadata": {},
   "source": [
    "1. Create Spark Session & Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f279f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original columns: ['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms', 'Avg. Area Number of Bedrooms', 'Area Population', 'Price', 'Address']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, avg, round as _round\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(\"USA_House_Pricing\").getOrCreate()\n",
    "\n",
    "# Load dataset\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"USA_Housing.csv\")\n",
    "\n",
    "print(\"Original columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3895f7f",
   "metadata": {},
   "source": [
    "Creates a Spark session and loads the USA House Pricing dataset into a PySpark DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e75ee8f",
   "metadata": {},
   "source": [
    "2. Rename columns to remove dots/spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdc90a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns: ['Avg_Area_Income', 'Avg_Area_House_Age', 'Avg_Area_Number_of_Rooms', 'Avg_Area_Number_of_Bedrooms', 'Area_Population', 'Price', 'Address']\n"
     ]
    }
   ],
   "source": [
    "df = (df\n",
    "      .withColumnRenamed(\"Avg. Area Income\", \"Avg_Area_Income\")\n",
    "      .withColumnRenamed(\"Avg. Area House Age\", \"Avg_Area_House_Age\")\n",
    "      .withColumnRenamed(\"Avg. Area Number of Rooms\", \"Avg_Area_Number_of_Rooms\")\n",
    "      .withColumnRenamed(\"Avg. Area Number of Bedrooms\", \"Avg_Area_Number_of_Bedrooms\")\n",
    "      .withColumnRenamed(\"Area Population\", \"Area_Population\")\n",
    ")\n",
    "\n",
    "print(\"Renamed columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3437e993",
   "metadata": {},
   "source": [
    "3. Data Cleaning (Handle Corrupted Rows)\n",
    "\n",
    "Some rows may have non-numeric data due to CSV misalignment.\n",
    "``We keep only rows where numeric columns are valid numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc3965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned numeric columns successfully\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = [\n",
    "    \"Avg_Area_Income\",\n",
    "    \"Avg_Area_House_Age\",\n",
    "    \"Avg_Area_Number_of_Rooms\",\n",
    "    \"Avg_Area_Number_of_Bedrooms\",\n",
    "    \"Area_Population\",\n",
    "    \"Price\"\n",
    "]\n",
    "\n",
    "# Remove rows where numeric data cannot be cast to double\n",
    "for c in numeric_cols:\n",
    "    df = df.filter(col(c).cast(\"double\").isNotNull())\n",
    "    df = df.withColumn(c, col(c).cast(\"double\"))\n",
    "\n",
    "print(\"Cleaned numeric columns successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66bd76",
   "metadata": {},
   "source": [
    "4. Basic Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb59a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------------+---------------------------+------------------+------------------+\n",
      "|summary|   Avg_Area_Income|Avg_Area_House_Age|Avg_Area_Number_of_Rooms|Avg_Area_Number_of_Bedrooms|   Area_Population|             Price|\n",
      "+-------+------------------+------------------+------------------------+---------------------------+------------------+------------------+\n",
      "|  count|              5000|              5000|                    5000|                       5000|              5000|              5000|\n",
      "|   mean| 68583.10898395971|  5.97722203528029|       6.987791850907942|         3.9813299999999967| 36163.51603857463|  1232072.65414236|\n",
      "| stddev|10657.991213830363|0.9914561798281722|      1.0058332312773866|         1.2341372654846832| 9925.650113501246|353117.62658106035|\n",
      "|    min|17796.631189543397| 2.644304186036705|      3.2361940234262048|                        2.0|172.61068627290044|15938.657923287848|\n",
      "|    max|107701.74837763935|  9.51908806613594|      10.759588335938624|                        6.5|  69621.7133777904|2469065.5941747027|\n",
      "+-------+------------------+------------------+------------------------+---------------------------+------------------+------------------+\n",
      "\n",
      "+----------+----------+\n",
      "| Avg_Price|Avg_Income|\n",
      "+----------+----------+\n",
      "|1232072.65|  68583.11|\n",
      "+----------+----------+\n",
      "\n",
      "+-------------------------------+------------------+\n",
      "|Address                        |Price             |\n",
      "+-------------------------------+------------------+\n",
      "|208 Michael Ferry Apt. 674     |1059033.5578701235|\n",
      "|188 Johnson Views Suite 079    |1505890.91484695  |\n",
      "|9127 Elizabeth Stravenue       |1058987.9878760849|\n",
      "|USS Barnett                    |1260616.8066294468|\n",
      "|06039 Jennifer Islands Apt. 443|1068138.0743935304|\n",
      "+-------------------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+----------+-------------+\n",
      "| Avg_Price|Avg_Income|Total_Records|\n",
      "+----------+----------+-------------+\n",
      "|1232072.65|  68583.11|         5000|\n",
      "+----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(numeric_cols).describe().show()\n",
    "\n",
    "df.select(\n",
    "    _round(avg(\"Price\"),2).alias(\"Avg_Price\"),\n",
    "    _round(avg(\"Avg_Area_Income\"),2).alias(\"Avg_Income\")\n",
    ").show()\n",
    "\n",
    "df.filter(col(\"Price\") > 1000000).select(\"Address\", \"Price\").show(5, truncate=False)\n",
    "\n",
    "# 5️⃣ Create SQL Table\n",
    "df.createOrReplaceTempView(\"house_data\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT ROUND(AVG(Price),2) AS Avg_Price,\n",
    "       ROUND(AVG(Avg_Area_Income),2) AS Avg_Income,\n",
    "       COUNT(*) AS Total_Records\n",
    "FROM house_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd8b457",
   "metadata": {},
   "source": [
    "5. Create SQL Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c804beae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------+\n",
      "| Avg_Price|Avg_Income|Total_Records|\n",
      "+----------+----------+-------------+\n",
      "|1232072.65|  68583.11|         5000|\n",
      "+----------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"house_data\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT ROUND(AVG(Price),2) AS Avg_Price,\n",
    "       ROUND(AVG(Avg_Area_Income),2) AS Avg_Income,\n",
    "       COUNT(*) AS Total_Records\n",
    "FROM house_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ff033e",
   "metadata": {},
   "source": [
    "6. Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a403f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols=numeric_cols, outputCols=[c + \"_imputed\" for c in numeric_cols])\n",
    "df = imputer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388b531",
   "metadata": {},
   "source": [
    "7. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37f8f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[c + \"_imputed\" for c in numeric_cols], outputCol=\"features\")\n",
    "df = assembler.transform(df)\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"features_norm\")\n",
    "df = scaler.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1bf0a3",
   "metadata": {},
   "source": [
    "8. Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0647974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler_std = StandardScaler(inputCol=\"features\", outputCol=\"features_std\", withMean=True, withStd=True)\n",
    "df = scaler_std.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e9e8de",
   "metadata": {},
   "source": [
    "9. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7978b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------------+--------------------+------------------+\n",
      "|Price             |Income_to_Price_Ratio|People_to_Room_Ratio|House_Age_2025    |\n",
      "+------------------+---------------------+--------------------+------------------+\n",
      "|1059033.5578701235|0.07511136732465279  |3293.790954438471   |2019.3171386783845|\n",
      "|1505890.91484695  |0.0526257524190456   |5968.524799526881   |2018.9971001917247|\n",
      "|1058987.9878760849|0.05787324113238965  |4332.5901952530185  |2019.13411015969  |\n",
      "|1260616.8066294468|0.0502494014938578   |6141.383426568383   |2017.8117639054813|\n",
      "|630943.4893385402 |0.0950674636306832   |3361.756070049812   |2019.9594454768937|\n",
      "+------------------+---------------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df = df.withColumn(\"Income_to_Price_Ratio\", col(\"Avg_Area_Income\") / col(\"Price\"))\n",
    "df = df.withColumn(\"People_to_Room_Ratio\", col(\"Area_Population\") / col(\"Avg_Area_Number_of_Rooms\"))\n",
    "df = df.withColumn(\"House_Age_2025\", lit(2025) - col(\"Avg_Area_House_Age\"))\n",
    "\n",
    "df.select(\"Price\", \"Income_to_Price_Ratio\", \"People_to_Room_Ratio\", \"House_Age_2025\").show(5, truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
